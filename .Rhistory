d<- cut(c2$Ranking,breaks=quantile(c2$Ranking,c(0,.2,.4,.6,.8,1)))
table(d)
table(d,c2$Income.Group)
flat(table(d,c2$Income.Group))
library(datasets)
library(plyr)
data("ToothGrowth")
var(ToothGrowth[ToothGrowth$supp=="VC"])
var(ToothGrowth$len[ToothGrowth$supp=="VC"])
var(ToothGrowth$len[ToothGrowth$supp=="OJ"])
mean(ToothGrowth$len[ToothGrowth$supp=="VC"])
mean(ToothGrowth$len[ToothGrowth$supp=="OJ"])
nrow(ToothGrowth$len[ToothGrowth$supp=="VC"])
length(ToothGrowth$len[ToothGrowth$supp=="VC"])
legnth(ToothGrowth$len[ToothGrowth$supp=="OJ"])
length(ToothGrowth$len[ToothGrowth$supp=="OJ"])
29*68.32723+29*43.63344
3246.859/58
sqrt(55.98033)
7.482*sqrt(2/30)
sqrt(1/15)
20.66333-16.96333
1.931844*2.009
3.7-3.881075
3.7+3.881075
var(ToothGrowth$len[ToothGrowth$dose==0.5])
var(ToothGrowth$len[ToothGrowth$dose==1.0])
mean(ToothGrowth$len[ToothGrowth$dose==0.5])
mean(ToothGrowth$len[ToothGrowth$dose==1.0])
length(ToothGrowth$len[ToothGrowth$dose==0.5])
length(ToothGrowth$len[ToothGrowth$dose==1.0])
(19*20.24787+19*19.49608)/(38)
19.735-10.605
sqrt(19.87197)*sqrt(1/10)
9.13+c(1,-1)*1.409688*2.021
var(ToothGrowth$len[ToothGrowth$dose==2.0])
a<-c(140,138,150,148,135)
b<-c(132,135,151,146,130)
c <- data.frame(a,b)
c
t.test(a~b,paired=TRUE,var.equal=TRUE,data=c)
t.test(a,b,paired=TRUE,var.equal=TRUE,data=c)
t.test(a,b,paired=TRUE,var.equal=FALSE,data=c)
1100+c(-1,1)*2.306*10
10/1787
.01*.99
(.01-0.005595971)/.0099
1787.100
1787/100
17.87-10
(.01*.99)*17.81
(.01*.99)*17.87
sqrt(0.176913)
7.87/0.4206103
.099/17.87
sqrt(0.005540011)
(.01-0.005595971)/0.07443125
power.t.test(power=0.9,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$n
power.t.test(n=100,delta=0.01,sd=0.04,type="one.sample",alt="one.sided")$power
(1.5^2+1.8^2)/2
sqrt(2.745)
4/sqrt(2.745)
+.087,+1077,+.31,.52,<.05,+N,+.8,+140,+larger
=4/1.6568
4/1.6568
sqrt(1.5^2/9+1.8^2/9)
sqrt((1.5^2)/9+(1.8^2)/9)
4/sqrt((1.5^2)/9+(1.8^2)/9)
((1.5^2)/9+(1.8^2)/9)/(((1.5^2)/9)^2/8+((1.8^2)/9)^2/8)
+.087,+1077,+.31,.52,+<.01,+N,+.8,+140,+larger
(.01-10/1787)
.01*.99/17.87
sqrt(.01*.99/17.87)
0.004404029/sqrt(.01*.99/17.87)
.01*.99*17.87
sqrt(.01*.99*17.87)
17.87-10
7.87/.4206103
.01*.99*1787
sqrt(17.6913)
7.87/4.206103
library(datasets)
data(mtcars)
mtcars
lm(mpg ~ am, data = data())
lm(mpg ~ am, data = data)
lm(mpg ~ am, data = dat)
dat <- mtcars
lm(mpg ~ am, data = dat)
lm(mpg ~ factor(am), data = dat)
ddply(dat, c("am"), summarise, mean = mean(mpg))
library(plyr)
ddply(dat, c("am"), summarise, mean = mean(mpg))
?mtcars
ddply(dat, c("am","wt"), summarise, mean = mean(mpg))
lm(mpg ~ factor(am), data = dat)
lm(mpg ~ factor(am), data = dat)$coeff
24.39231-7.244939
g = ggplot(dat, aes(x = am, y = mpg)) + xlab("Automatic/Manual") + ylab("MPG")
g = g + geom_smooth(method = "lm", color = "red")
g = ggplot(dat, aes(x = am, y = mpg)) + xlab("Automatic/Manual") + ylab("MPG")
library(ggplot2)
g = ggplot(dat, aes(x = am, y = mpg)) + xlab("Automatic/Manual") + ylab("MPG")
g = g + geom_smooth(method = "lm", color = "red")
g
g = g + geom_point(size = 5, color = "blue")
g
anova(lm(mpg ~ factor(am), data = dat))
summary(lm(mpg ~ factor(am), data = dat))
?lm
a<-lm(mpg ~ factor(am), data = dat)
a$qr
a$effects
a$terms
a$assign
a$call
a$model
a$coefficients
a$residuals
summary(lm(mpg ~ factor(am), data = dat))$r.squared
lm(mpg ~ factor(am) + disp, data = dat)
summary(lm(mpg ~ factor(am) + disp, data = dat))
summary(lm(mpg ~ factor(am) + wt, data = dat))
?mtcars
summary(lm(mpg ~ factor(am) + hp, data = dat))
summary(lm(mpg ~ factor(am) + hp + wt + disp, data = dat))
corr(hp,wt)
correl(hp,wt)
cor(hp,wt)
a<-lm(mpg ~ factor(am) + hp + wt + disp, data = dat)
vif(a)
library(Car)
library(car)
install.packages(car)
install.packages(usdm)
install.packages(usdm)
install.packages("car")
vif(a)
library(car)
vif(a)
b<-lm(mpg ~ factor(am) + hp + wt, data = dat)
vif(b)
a<-lm(mpg ~ factor(am) + hp + wt + disp + factor(cyl), data = dat)
vif(a)
b<-lm(mpg ~ factor(am) + hp + wt + factor(cyl), data = dat)
vif(b)
summary(b)$r.squared
summary(a)$r.squared
c<-lm(mpg ~ factor(am) + hp + wt, data = dat)
vif(c)
summary(c)$r.squared
summary(c)
cor(mtcars$mpg)
cor(mtcars)
cor(mtcars)$mpg
typeof(cor(mtcars))
d <- data.frame(cor(mtcars))
d
d$mpg
a <- lm(mpg ~ factor(am) + hp + wt + disp + factor(cyl), data = dat)
summary(a)$r.squared
vif(a)
b <- lm(mpg ~ factor(am) + hp + wt, data = dat)
summary(b)$r.squared
vif(b)
summary(b)
f<-lm(lm(mpg ~ factor(am), data = dat))
plot(mtcars$am,resid(f))
ggplot(dat, aes(resid(c))) + stat_qq()
ggplot(dat, aes(sample = resid(c))) + stat_qq()
dfbetas(c)
c
cooks.distance(c)
hatvalues(c)
round(hatvalues,3)
round(hatvalues(c),3)
round(dfbetas(c),3)
round(cooks.distance(c),2)
typeof(round(cooks.distance(c),2))
order(round(cooks.distance(c),2))
order(round(cooks.distance(c),2),decreasing=TRUE)
h<-round(cooks.distance(c),2)
h[order(h)[1:5]]
h[order(h, decreasing = TRUE)[1:5]]
vif(b)
vif(a)
?vif
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
plot(concrete$CompressiveStrength)
plot(concrete$CompressiveStrength,col=concrete$Age)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
plot(concrete$CompressiveStrength,col=concrete$FlyAsh)
IL_str <- grep("^IL", colnames(training), value = TRUE)
IL_str
preProc <- preProcess(training[, IL_str], method = "pca", thresh = 0.8)
preProc
predictors_IL <- predictors[, IL_str]
df <- data.frame(diagnosis, predictors_IL)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
set.seed(3433)
inTrain = createDataPartition(df$diagnosis, p = 3/4)[[1]]
training = df[inTrain, ]
testing = df[-inTrain, ]
modelFit <- train(diagnosis ~ ., method = "glm", data = training)
predictions <- predict(modelFit, newdata = testing)
confusionMatrix(predictions, testing$diagnosis)
swirl()
library(swirl)
swirl()
swirl()
5+7
x <- 5 + 7
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
x <- data.frame(segmentationOriginal)
train <- x[x$Case=="Train",]
test <- x[x$Case=="Test",]
model <- train(class ~ ., data = train, method="rcart")
model$finalModel
x <- data.frame(segmentationOriginal)
train <- x[x$Case=="Train",]
test <- x[x$Case=="Test",]
model <- train(Class ~ ., data = train, method="rcart")
model$finalModel
x <- data.frame(segmentationOriginal)
train <- x[x$Case=="Train",]
test <- x[x$Case=="Test",]
model <- train(Class ~ ., data = train, method="rcart")
x <- data.frame(segmentationOriginal)
train <- x[x$Case=="Train",]
test <- x[x$Case=="Test",]
model <- train(Class ~ ., data = train, method="rpart")
model$finalModel
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
y <- olive
str(y)
model2 <- train(Area~.,data=y,method="rpart")
model2$finalModel
predict(model2,newdata=newdata)
predict(model2,newdata)
newdata
unique(y$Area)
head(y)
tail(area)
tail(y)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
z<-SAheart
str(z)
z1<-z[,c(z$tobacco,z$ldl,z$typea,z$obesity,z$alcohol,z$age,z$chd)]
z1<-z[,c("tobacco","ldl","typea","obesity","alcohol","age","chd")]
str(z1)
model3 <- train(chd ~ ., data = z1, method="glm",family="binomial")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
z1<-trainSA[,c("tobacco","ldl","typea","obesity","alcohol","age","chd")]
model3 <- train(chd ~ ., data = z1, method="glm",family="binomial")
z2 <- testSA[,c("tobacco","ldl","typea","obesity","alcohol","age","chd")]
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
z1<-trainSA[,c("tobacco","ldl","typea","obesity","alcohol","age","chd")]
model3 <- train(chd ~ ., data = z1, method="glm",family="binomial")
z2 <- testSA[,c("tobacco","ldl","typea","obesity","alcohol","age","chd")]
function(z1$chd,predict(model3,z1)){sum(((predict(model3,z1) > 0.5)*1) != z1$chd)/length(z1$chd)}
function(chd,predict(model3,z1)){sum(((predict(model3,z1) > 0.5)*1) != chd)/length(chd)}
a<-predict(model3,z1)
b<-z1$chd
head(a)
head(b)
function(b,a){sum(((a > 0.5)*1) != b)/length(b)}
sum(((a > 0.5)*1) != b)/length(b)
a<-predict(model3,z2)
b<-z2$chd
sum(((a > 0.5)*1) != b)/length(b)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
a<-vowel.train
str(a)
a$y <- factor(a$y)
str(a)
b<-vowel.test
b$y <- factor(b$y)
set.seed(33833)
modfit <- train(y~.,data=a,method="rf",prox=TRUE)
rfNews()
varImp(modfit)
c<-rbind(a,b)
modfit <- train(y~.,data=c,method="rf",prox=TRUE)
varImp(modfit)
setwd("C:\\Users\\brian\\Documents\\MachLearn")
---
title: "Machine Learning Project"
output: html_document
---
Summary
```{r}
library(parallel)
library(doParallel)
library(caret)
dat <- data.frame(read.csv("pml-training.csv"))
a <- colnames(dat)
b<-c(grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dat2 <- dat[,-b]
set.seed(33833)
inTrain = createDataPartition(dat2$classe, p = 3/4)[[1]]
training = dat2[ inTrain,]
testing = dat2[-inTrain,]
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
fitrf <- train(classe ~ ., method="rf",data=training,trControl = fitControl, prox = TRUE)
stopCluster(cluster)
#fitgbm <- train(classe ~.,data=training,method="gbm",trControl = fitControl,verbose=FALSE)
#fitlda <- train(classe ~.,data=training,method="lda",trControl = fitControl,verbose=FALSE)
predrf <- predict(fitrf,testing)
#predgbm <- predict(fitgbm,testing)
#predlda <- predict(fitlda,testing)
confusionMatrix(predrf, testing$classe)
fitrf
dattest <- data.frame(read.csv("pml-testing.csv"))
dattest2 <- dattest[,-b]
confusionMatrix(predict(predrf,dattest2), dattest2$classe)
confusionMatrix(predict(fitrf,dattest2), dattest2$classe)
dattest2
nrow(dattest2)
ncol(dattest2)
ncol(dat2)
predict(fitrf,dattest2)
fitrf
fitrf$finalModel
confusionMatrix(training)
fitrf
str(dat)
confusionMatrix(predict(fitrf,dattest2), dattest2$classe)
predict(fitrf,dattest2)
confusionMatrix(predrf, testing$classe)
fitrf$results
fitrf$terms
fitrf
fitrf$finalModel
fitrf$results
predict(fitrf,dattest2)
dattest <- data.frame(read.csv("pml-testing.csv"))
dattest2 <- dattest[,-b]
predict(fitrf,dattest2)
dattest2
dattest <- data.frame(read.csv("pml-testing.csv"))
a <- colnames(dattest)
b<-c(grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
predict(fitrf,dattest2)
ddattest
dattest2
nrow(dattest2)
ncol(dattest2)
ncol(testing)
colNames(testing)
colnames(testing)
colnames(dattest2)
dattest2$problem_id
dattest2$classe <- dattest2$problem_id
predict(fitrf,dattest2)
predict(fitrf,testing)
testing$classe
a <- colnames(dat)
b<-c(grep("name",a),grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dat2 <- dat[,-b]
ncol(dat2)
str(dattest2)
str(training)
fitrf$finalModel
?train
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl, prox = TRUE)
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl)
head(training)
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl)
stopCluster(cluster)
fitlda
fitlda$finalModel
predict(fitlda,dattest2)
dattest <- data.frame(read.csv("pml-testing2.csv"))
a <- colnames(dattest)
b<-c(grep("name",a),grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
predict(fitlda,dattest2)
getwd()
dattest <- data.frame(read.csv("pml-testing2.csv"))
a <- colnames(dattest)
b<-c(grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
predict(fitlda,dattest2)
str(dattest2)
str(training)
dattest <- data.frame(read.csv("pml-testing2.csv"),na.strings=c("NA",""))
a <- colnames(dattest)
b<-c(grep("name",a),grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
predict(fitrf,dattest2)
b<-c(grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
predict(fitrf,dattest2)
fitlda
fitlda$finalModel
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl, prox = TRUE)
predict(fitlda,dattest2)
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl)
predict(fitlda,dattest2)
summary(dattest2)
summary(testing)
fitlda$finalModel
dattest <- data.frame(read.csv("pml-testing.csv"))
a <- colnames(dattest)
b<-c(grep("name",a),grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
colnames(dattest2)
dat <- data.frame(read.csv("pml-training.csv"))
a <- colnames(dat)
b<-c(grep("name",a),grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dat2 <- dat[,-b]
colnames(dat2)
set.seed(33833)
inTrain = createDataPartition(dat2$classe, p = 3/4)[[1]]
training = dat2[ inTrain,]
testing = dat2[-inTrain,]
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
fitlda <- train(classe ~ ., method="lda",data=training,trControl = fitControl, prox = TRUE)
stopCluster(cluster)
colnames(dattest2)
predict(fitlda,dattest2)
fitlda$finalModel
summary(dattest2)
summary(training)
summary(testing)
predrf
str(predrf)
str(predict(fitrf,dattest2))
str(predict(fitlda,dattest2))
dattest <- data.frame(read.csv("pml-testing2.csv"))
a <- colnames(dattest)
b<-c(grep("name",a),grep("min",a),grep("max",a),grep("total",a),grep("var",a),grep("stddev",a),grep("kurtosis",a),grep("avg",a),grep("skewness",a),grep("window",a),grep("time",a),grep("amplitude",a))
dattest2 <- dattest[,-b]
predict(fitlda,dattest2)
str(training)
training2 <- training[,-X]
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
fitControl <- trainControl(method = "cv",number = 5,allowParallel = TRUE)
fitlda <- train(classe ~ . - X, method="lda",data=training,trControl = fitControl, prox = TRUE)
stopCluster(cluster)
fitlda
fitlda$finalModel
